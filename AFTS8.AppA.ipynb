{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 8 Appendix A: Review of vectors and matrices\n",
    "\n",
    "[All these images are broken - see \"AFTS3 from 3.6\"]\n",
    "\n",
    "Review of algebra and properties of vectors and matrices:\n",
    "\n",
    "An m x n real-valued matrix is an m x n array of real numbers. \n",
    "\n",
    "For example:\n",
    "\n",
    "$$\\large A = \n",
    "\\begin{bmatrix}\n",
    "2 & 5 & 8\\\\\n",
    "-1 & 3 & 4\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "is a 2 x 3 matrix with 2 rows and 3 columns.  \n",
    "\n",
    "Generally, an m x n matrix is written:\n",
    "\n",
    "(8.46)\n",
    "\n",
    "$$\\large A \\equiv [a_{ij}] =\n",
    "\\begin{bmatrix}\n",
    "a_{11} & a_{12} & \\dots & a_{1,n-1} & a_{1n} \\\\\n",
    "a_{21} & a_{22} & \\dots & a_{2,n-1} & a_{2n} \\\\\n",
    "\\vdots & \\vdots &  & \\vdots & \\vdots \\\\\n",
    "a_{m1} & a_{m2} & \\dots & a_{m,n-1} & a_{mn} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- m and n are positive integers denoting row dimension and column dimension of A\n",
    "- $a_{ij}$ is referred to as the (i,j)th element of A.  \n",
    "- $a_{ii}$ are the **diagonal** elements of the matrix.\n",
    "- an m x 1 matrix forms an m-dimensional **column vector**.\n",
    "- 1 x n matrix is an n-dimensional row vector.\n",
    "- in literature, a vector is often meant to be a column vector.\n",
    "- if m = n then the matrix is a sqaure matrix. \n",
    "- if $a_{ij} = 0 for i ≠ j$ then matrix A is **a diagonal matrix**\n",
    "- if $a_{ij}$ = 0 for i ≠ j and $a_{ii} = 1$ for all i, then A is the m x m **identity matrix**, commonly denoted by $I_m$ or **I** if the dimension is clear.\n",
    "- the notation $A' = [a_{ij}'$ denotes the transpose of A:\n",
    "    - from the definition, $a_{ij}' = a_{ji}$\n",
    "    - (A')' = A\n",
    "    - if A' = A then A is a **symmetric matrix**.\n",
    "- the n x m matrix A' is the **transpose** of the matrix A [notice m is still the first subscript]:\n",
    "\n",
    "$$\\large A' =\n",
    "\\begin{bmatrix}\n",
    "a_{11} & a_{21} & \\dots & a_{m-1,1} & a_{m1} \\\\\n",
    "a_{12} & a_{22} & \\dots & a_{m-1,2} & a_{m2} \\\\\n",
    "\\vdots & \\vdots &  & \\vdots & \\vdots \\\\\n",
    "a_{1n} & a_{2n} & \\dots & a_{m-1,n} & a_{mn} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "For example:\n",
    "\n",
    "$$\\large\n",
    "\\begin{bmatrix}\n",
    "2 & -1 \\\\\n",
    "5 & 3 \\\\\n",
    "8 & 4 \\\\\n",
    "\\end{bmatrix}\n",
    "\\text{ is the transpose of }\n",
    "\\begin{bmatrix}\n",
    "2 & 5 & 8\\\\\n",
    "-1 & 3 & 4\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "### Basic operations\n",
    "\n",
    "Suppose $A = [a_{ij}]_{\\text{m x n}}$ and $C = [a_{ij}]_{\\text{p x q}}$ are two matrices with dimensions given in their subscripts.  Let *b* be a real number.  Define basic matrix operations:\n",
    "\n",
    "- Addition: $A + C = [a_{ij} + c_{ij}]_{\\text{m x n}}$ if m = p and n = q.\n",
    "- Subtraction: $A - C = [a_{ij} - c_{ij}]_{\\text{m x n}}$ if m = p and n = q.\n",
    "- Scalar multiplication: $bA = [ba_{ij}]_{\\text{m x n}}$\n",
    "- Multiplication: $AC = [ \\sum_{v=1}^n a_{iv}c_{vj} ]_{\\text{m x n}}$ provided n = p.\n",
    "\n",
    "When the dimensions of matrices satisfy the condition for multiplication to take place, the two matrices are said to be **conformable**.  For example:\n",
    "\n",
    "\n",
    "$$\\large\n",
    "\\begin{align}\n",
    "\\begin{bmatrix}\n",
    "2 & 1 \\\\\n",
    "1 & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "1 & 2 & 3\\\\\n",
    "-1 & 2 & -4\n",
    "\\end{bmatrix}\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "2 \\times 1 - 1 \\times 1 & 2 \\times 2 + 1 \\times 2 & 2 \\times 3 - 1 \\times 4\\\\\n",
    "1 \\times 1 - 1 \\times 1 & 1 \\times 2 + 1 \\times 2 & 1 \\times 3 - 1 \\times 4\n",
    "\\end{bmatrix}\\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "1 & 6 & 2\\\\\n",
    "0 & 4 & -1\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Important rules of matrix operations include:\n",
    "- (a) (AC)' = C'A'\n",
    "- (b) AC ≠ CA in general\n",
    "\n",
    "### Inverse, Trace, Eigenvalue and Eigenvector\n",
    "\n",
    "A square matrix $A_{\\text{m x m}}$ is **nonsingular** or **invertible** \n",
    "- if there exists a unque matrix $C_{\\text{m x m}}$ such that $AC = I_m$ = the m x m identity matrix.  \n",
    "- **C** is called the inverse matrix of **A** \n",
    "- **C** is denoted C = $A^{-1}$\n",
    "\n",
    "The **trace** of $A_{\\text{m x m}}$ is the sum of its diagonal elememts:\n",
    "\n",
    "$$\\large \\text{tr(A) = }\\sum_{i=1}^m a_{ii}$$\n",
    "\n",
    "[the above works if i < j when matrix is short and wide, but if j<i and tall and thin, then I would suggest: \n",
    "                                     \n",
    "$$\\large \\text{tr(A) = }\\sum_{j=1}^m a_{jj}$$\n",
    "\n",
    "- $\\large tr(A + C) = tr(A) + tr(C)$\n",
    "- $\\large tr(A) = tr(A')$\n",
    "- $\\large tr(AC) = tr(CA)$ provided that the two matrices are conformable.\n",
    "\n",
    "A number $\\large \\lambda$ and an *m x 1 vector **b*** possibly complex valued are a **right eigenvalue** and **eigenvector** pair of the matrix **A** if **Ab = $\\gamma$b**:\n",
    "- there are m possible eigenvalues for the matrix **A**\n",
    "- for a real-valued matrix **A** complex eigenvalues occur in conjugated pairs.\n",
    "- the matrix **A** is nonsingular IFF all eigenvalues are nonzero.\n",
    "- denote eigenvalues \n",
    "\n",
    "$\\large \\{\\lambda_i| i = 1, \\ldots, m\\}$:\n",
    "\n",
    "- [relationship of trace to eigenvalues:]\n",
    "\n",
    "    $$\\large \\text{tr(A) =} \\sum_{i=1}^m a_{ii} = \\sum_{i=1}^m \\lambda_i$$\n",
    "    \n",
    "\n",
    "- **determinant** of matrix A can be defined as \n",
    "\n",
    "    $$\\large \\vert A \\lvert = \\prod_{i=1}^m \\lambda_i$$\n",
    "    \n",
    "   \n",
    "Graybill (1969) is the reference text for this material and in particular the determininant.\n",
    "\n",
    "- the **rank** of a matrix $A_{\\text{m x m}}$ is the number of nonzero eigenvalues of the symmetric matrix **AA'**.  [So multiply AA' and find out the number of nonzero eigenvalues and you've the rank of A.]\n",
    "\n",
    "- For a nonsingular matrix A, the inverse of the transpose equals the transpose of the inverse:\n",
    "\n",
    "$$\\large (A^{-1})' = (A')^{-1}$$\n",
    "\n",
    "### Positive-Definite matrix\n",
    "\n",
    "A square matrix A (m x m) is a **positive definite** matrix if \n",
    "- A is symmetric and\n",
    "- all eigenvalues of A are positive\n",
    "\n",
    "Alternatively, a [rectangular] matrix A is a **positive definite** matrix if for any nonzero m-dimensional vector b, **b'Ab** > 0.  [To satidfy myself that b'Ab is a a real value and not a matrix, I considered this:\n",
    "- if b can multiply from right then $n_A = m_b$\n",
    "- if b' can multiply from left then $m_b = A_m$\n",
    "- so **b'A** is [1 x m][m x n] = [1 x n] and **b'Ab** is [1 x m][m x n][n x 1] = 1x1 and can be evaluated as > 0 or not.]\n",
    "\n",
    "Properties of **positive definite matrix A**\n",
    "- all eigenvlues of **A** are real and positive\n",
    "- the matrix can be decomposed in what is referred to as the **spectral decompostion** of the matrix A:\n",
    "\n",
    "$$\\large A = P \\Lambda P'$$\n",
    "\n",
    "\n",
    "where:\n",
    "- $\\large \\mathbf{\\Lambda}$ is diagonal matrix consisting of all eigenvalues [$\\lambda_i$] of A \n",
    "- $\\large \\mathbf{P}$ is an m x m matrix of the m right eigenvectors of A.\n",
    "\n",
    "It is common to write the eigenvalues as:\n",
    "\n",
    "$$\\large \\lambda_1 ≥ \\lambda_1 ≥  \\cdots ≥ \\lambda_m$$\n",
    "\n",
    "and the eigenvectors as \n",
    "\n",
    "$$\\large e_1, \\cdots, e_m$$\n",
    "\n",
    "such that \n",
    "\n",
    "$$\\large Ae_i = \\lambda_i e_i$$ \n",
    "\n",
    "... and the eigenvectors are of unit length and orthogonal --> the matrix P [that holds them] is referred to as an **orthogonal matrix**.  [vectors are normalized to unit length by the $\\lambda_i$ in $\\Lambda$.]\n",
    "\n",
    "$$\\large e_i'e_i = 1$$\n",
    "\n",
    "$$\\large e_i'e_j = 0 \\text{ if i ≠ j and if the eigenvalues are distinct}$$ \n",
    "\n",
    "For example, the matrix $\\large \\Sigma$ is **positive definite**:\n",
    "\n",
    "$$\\large \\Sigma =\n",
    "\\begin{align}\n",
    "\\begin{bmatrix}\n",
    "2 & 1 \\\\\n",
    "1 & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align}$$\n",
    "\n",
    "\n",
    "- these simple calculations show that \n",
    "    - 3 and 1 are eigenvalues of $\\large \\Sigma$ \n",
    "    - with normalzed egenvectors $\\large (\\frac{1}{\\sqrt{2}}, \\frac{1}{\\sqrt{2}})'$ and $\\large (\\frac{1}{\\sqrt{2}}, -\\frac{1}{\\sqrt{2}})'$ respectively:\n",
    "\n",
    "[here are those simlpe calculations that show the eigenvalues and eigenvectors relating to each other and to $\\large \\Sigma$]:\n",
    "\n",
    "$$\\large\n",
    "\\begin{bmatrix}\n",
    "2 & 1 \\\\\n",
    "1 & 2 \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "1 \\\\\n",
    "\\end{bmatrix}=\n",
    "3\n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "1 \\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "\n",
    "$$\\large\n",
    "\\begin{bmatrix}\n",
    "2 & 1 \\\\\n",
    "1 & 2 \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "-1 \\\\\n",
    "\\end{bmatrix}=\n",
    "1\n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "1 \\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Spectral decomposition holds if one can verify that\n",
    "\n",
    "\n",
    "$$\\large\n",
    "\\begin{bmatrix}\n",
    "\\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{2}} \\\\\n",
    "\\frac{1}{\\sqrt{2}} & -\\frac{1}{\\sqrt{2}} \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "2 & 1 \\\\\n",
    "1 & 2 \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{2}} \\\\\n",
    "\\frac{1}{\\sqrt{2}} & -\\frac{1}{\\sqrt{2}} \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "2 & 1 \\\\\n",
    "1 & 2 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "[where:]\n",
    "- [the eigenvectors are normalized to unit length:]  \n",
    "$\\large \\sqrt{(\\frac{1}{\\sqrt{2}})^2 + (\\frac{1}{\\sqrt{2}})^2} = 1$   \n",
    "$\\large \\sqrt{(\\frac{1}{\\sqrt{2}})^2 + (-\\frac{1}{\\sqrt{2}})^2} = 1$ \n",
    "\n",
    "- [the eigenvectors are orthogonal:]   \n",
    "$\\large (\\frac{1}{\\sqrt{2}}, \\frac{1}{\\sqrt{2}})' (\\frac{1}{\\sqrt{2}}, -\\frac{1}{\\sqrt{2}}) = 0$\n",
    "\n",
    "\n",
    "#### Cholesky decomposition\n",
    "\n",
    "For a symmetric matrix **A** there exists \n",
    "- a lower triangular matrix **L** with diagonal elements being 1, and\n",
    "- a diagonal matrix **G** such that [references Strang (1980):\n",
    "\n",
    "$$\\large A = LGL'$$\n",
    "\n",
    "where:\n",
    "- if **A** is positive definite, then the diagonal elements of **G** are positive [and the decomposition proceeds further] to what is called the **Cholesky decomposition** of A:\n",
    "\n",
    "$$\\large \\mathbf A = L\\sqrt{G}\\sqrt{G}L' = (L\\sqrt{G})(L\\sqrt{G})'$$\n",
    "\n",
    "- $\\large \\mathbf L \\sqrt{G}$ is **also** a lower triangular matrix\n",
    "- the square root is taken element by element.\n",
    "- the decomposition shows that a positive-definite matrix **A** can be diagonalized as \n",
    "\n",
    "$$\\large \\mathbf L^{-1}A(L')^{-1} = L^{-1} A (L^{-1})' = G$$\n",
    "\n",
    "[where G is the collection of eigenvalues $\\lambda_i$ that can replace matrix A as was stated above: $\\large \\mathbf Ab = \\lambda b$. So, it makes sense that rearranging the Cholesky's decomposition that decomposes A into its eigenvectors and eigenvalues would result in diagonalized A in the form of the collection of $\\large \\lambda_i$ denoted $\\large \\Lambda$.]\n",
    "\n",
    "Since **L** is a lower triangular matrix with unit diagonal elements, $\\large L^{-1}$ is also a lower triangular matrix with unit diagonal elements.  Consider e.g. the prior 2 x 2 matrix $\\large \\Sigma$ for which it's easy to verify that these satisfy $\\large \\mathbf \\Sigma = LGL'$\n",
    "\n",
    "$$\\large \n",
    "\\mathbf{L} = \n",
    "\\begin{bmatrix}\n",
    "1.0 & 0.0 \\\\\n",
    "0.5 & 1.0 \\\\\n",
    "\\end{bmatrix}\n",
    "\\text{ and }\n",
    "\\mathbf{G} = \n",
    "\\begin{bmatrix}\n",
    "2.0 & 0.0 \\\\\n",
    "0.5 & 1.5 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Additionally:\n",
    "\n",
    "$$\\large \n",
    "\\mathbf{L}^{-1} = \n",
    "\\begin{bmatrix}\n",
    "1.0 & 0.0 \\\\\n",
    "-0.5 & 1.0 \\\\\n",
    "\\end{bmatrix}\n",
    "\\text{ and }\n",
    "\\mathbf L^{-1}\\Sigma(L^{-1})' = G$$\n",
    "\n",
    "### Vectorization and Kronecker Product\n",
    "\n",
    "Writing an m x n matrix **A** in its columns as:\n",
    "\n",
    "$$\\large \\mathbf A = [a_1, \\ldots, a_n]$$, \n",
    "\n",
    "[here, you are looking at the matrix represented by matrix columns denoted by $\\mathbf a_1, \\ldots, a_n$ in a list denoted by brackets.]\n",
    "\n",
    "define **the stacking operation** [\"*vectorization*\"] as: \n",
    "\n",
    "$$\\large \\text{vec(A) } = (a_1', a_2', \\ldots, a_m')'$$ \n",
    "\n",
    "[here you are looking at the matrix rows denoted by $\\mathbf a_1', \\ldots, a_m'$ containted in a vector denoted by $(\\ldots)$'.\n",
    "\n",
    "which is an *mn x 1* vector.\n",
    "\n",
    "[Parentheses () denote vector and brackets [] denote matrices: His example supports the second, not this first bullet here:\n",
    "- $\\large \\text{vec(A) } = (a_1', a_2', \\ldots, a_m')' = ((a_{11}, a_{12}, \\ldots, a_{1n}),(a_{21}, a_{22}, \\ldots, a_{2n}), \\ldots, (a_{m1}, a_{m2}, \\ldots, a_{mn}))'$  \n",
    "- $\\large \\text{vec(A) } = (a_1', a_2', \\ldots, a_n')' = ((a_{11}, a_{21}, \\ldots, a_{m1}),(a_{12}, a_{22}, \\ldots, a_{m2}), \\ldots, (a_{1n}, a_{2n}, \\ldots, a_{mn}))'$ \n",
    "- This is not a matrix but a vector that has a quantity of rows = m*n and 1 column.  \n",
    "- In these representation directly above, ' outside the $(\\ldots)$ indicates transpose because it is a vector on its side when written in the book, but it is mn x 1 or mn tall and 1 thin.]\n",
    "\n",
    "For 2 matrices $\\large \\mathbf{A}_{\\text{m x n}}$ and $\\large \\mathbf{C}_{\\text{p x q}}$, the **Kronecker product** between **A** and **C** is:\n",
    "\n",
    "$$\\large \\mathbf{A} \\bigotimes \\mathbf{C} = \n",
    "\\begin{bmatrix}\n",
    "a_{11}\\mathbf{C} & a_{12}\\mathbf{C} & \\cdots & a_{1n}\\mathbf{C}&\\\\\n",
    "a_{21}\\mathbf{C} & a_{22}\\mathbf{C} & \\cdots & a_{2n}\\mathbf{C}&\\\\\n",
    "\\vdots & \\vdots & & \\vdots\\\\\n",
    "a_{m1}\\mathbf{C} & a_{m2}\\mathbf{C} & \\cdots & a_{mn}\\mathbf{C}&\\\\\n",
    "\\end{bmatrix}_{\\text{mp x nq}}$$\n",
    "\n",
    "For example, \n",
    "\n",
    "$$\\large \n",
    "\\mathbf{A} = \n",
    "\\begin{bmatrix}\n",
    "2 & 1 \\\\\n",
    "-1 & 3 \\\\\n",
    "\\end{bmatrix}, \\;\\;\n",
    "\\mathbf{C} = \n",
    "\\begin{bmatrix}\n",
    "4 & -1 & 3 \\\\\n",
    "-2 & 5 & 2 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Then ...\n",
    "\n",
    "$\\large \\text{vec} (\\mathbf{A}) \\text{= (2, -1, 1, 3)'}$\n",
    "\n",
    "$\\large \\text{vec} (\\mathbf{C}) \\text{= (4, -2, -1, 5, 3, 2)'}$\n",
    "\n",
    "\n",
    "$$\\begin{align} \\large \\mathbf{A} \\bigotimes \\mathbf{C} &= \n",
    "\\begin{bmatrix}\n",
    "2 \\times \\begin{bmatrix}4 & -1 & 3 \\\\ -2 & 5 & 2 \\end{bmatrix} & 1 \\times \\begin{bmatrix}4 & -1 & 3 \\\\ -2 & 5 & 2 \\end{bmatrix} \\\\\n",
    "-1 \\times \\begin{bmatrix}4 & -1 & 3 \\\\ -2 & 5 & 2 \\end{bmatrix} & 3 \\times \\begin{bmatrix}4 & -1 & 3 \\\\  -2 & 5 & 2 \\end{bmatrix} \\end{bmatrix}\\\\\n",
    "&= \\begin{bmatrix}\n",
    "\\begin{bmatrix}8 & -2 & 6 \\\\ -4 & 10 & 4 \\end{bmatrix} & \\begin{bmatrix}4 & -1 & 3 \\\\ -2 & 5 & 2 \\end{bmatrix} \\\\\n",
    "\\begin{bmatrix}-4 & 1 & -3 \\\\ 2 & -5 & -2 \\end{bmatrix} & \\begin{bmatrix}12 & -3 & 9 \\\\  -6 & 15 & 6 \\end{bmatrix} \\end{bmatrix}\\\\\n",
    "&=\\begin{bmatrix}\n",
    "8 & -2 & 6 & 4 & -1 & 3 \\\\\n",
    "-4 & 10 & 4 & -2 & 5 & 2 \\\\\n",
    "-4 & 1 & -3 & 12 & -3 & 9 \\\\\n",
    "2 & -5 & -2 & -6 & 15 & 6 \n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Assuming that the dimensions are appropriate, the following properties are available for the two operators:\n",
    "1. $\\large \\mathbf{A} \\bigotimes \\mathbf{C} ≠ \\mathbf{C} \\bigotimes \\mathbf{A} \\text{ in general.}$   \n",
    "2. $\\large (\\mathbf{A} \\bigotimes \\mathbf{C})' = \\mathbf{A}' \\bigotimes \\mathbf{C}' $.\n",
    "3. $\\large \\mathbf{A} \\bigotimes (\\mathbf{C + D}) =  \\mathbf{A} \\bigotimes \\mathbf{C} + \\mathbf{A} \\bigotimes \\mathbf{D}$.\n",
    "4. $\\large (\\mathbf{A} \\bigotimes \\mathbf{C}) (\\mathbf{F} \\bigotimes \\mathbf{G}) = (\\mathbf{AF}) \\bigotimes (\\mathbf{CG})$.\n",
    "5. $\\large \\text{If A and C are invertible, then } (\\mathbf{A} \\bigotimes \\mathbf{C})^{-1} = \\mathbf{A}^{-1} \\bigotimes \\mathbf{C}^{-1}$\n",
    "6. $\\large \\text{For square matrices A and C, tr}(\\mathbf{A} \\bigotimes \\mathbf{C}) = tr(\\mathbf{A}) tr(\\mathbf{C})$\n",
    "7. vec(**A** + **C**) = vec(**A**) + vec(**C**).\n",
    "8. $\\large \\text{vec(ABC)} = (C' \\bigotimes A) \\text{vec(B).}$\n",
    "9. tr(**AC**) = vec(**C**')' vec(**A**) = vec(**A**')'vec(**C**).\n",
    "10. $\\large \\begin{align} \\text{tr(ABC)} &= \\text{vec}(\\mathbf{A}')(\\mathbf{C}' \\bigotimes \\mathbf{I}) \\text{vec}(\\mathbf{B}) &= \\text{vec}(\\mathbf{A'})' (\\mathbf{I} \\bigotimes \\mathbf{B})  \\text{vec}(\\mathbf{C})\\\\\n",
    "&= \\text{vec}(\\mathbf{B}')(\\mathbf{A}' \\bigotimes \\mathbf{I}) \\text{vec}(\\mathbf{C}) &= \\text{vec}(\\mathbf{B'})' (\\mathbf{I} \\bigotimes \\mathbf{C})  \\text{vec}(\\mathbf{A})\\\\\n",
    "&= \\text{vec}(\\mathbf{C}')(\\mathbf{B}' \\bigotimes \\mathbf{I}) \\text{vec}(\\mathbf{A}) &= \\text{vec}(\\mathbf{C'})' (\\mathbf{I} \\bigotimes \\mathbf{A})  \\text{vec}(\\mathbf{B}) \\end{align}$\n",
    "\n",
    "\n",
    "Multivariate statistical analysis often deals with symmetric matrices.  It is therefore convenient to generalize the stacking operation to the **half-stacking** operation that consists of elements on or below the main diagonal.  Specificaslly, for a symmetric square matrix $\\large \\mathbf{A} = [a_{ij}]_{\\text{k x k}}$ define:\n",
    "\n",
    "$$\\large vech(\\mathbf{A}) = (\\mathbf{a}_{1.}', \\mathbf{a}_{2*}', \\ldots, \\mathbf{a}_{k*}')'$$\n",
    "\n",
    "where:\n",
    "- $\\large \\mathbf{a}_1$ is the first column of **A** \n",
    "- $\\large \\mathbf{a}_{i*} = (a_{ii}, a_{i+1,i}, \\ldots, a_{ki})'$ is a (k - i + 1) dimensional vector.\n",
    "- The dimension of vech(**A**) is $\\large k\\frac{(k + 1)}{2}$\n",
    "\n",
    "For example, suppose that k = 3.  Then $\\large vech(\\mathbf{A}) = (a_{11}, a_{21}, a_{31}, a_{22}, a_{32}, a_{33})'$ which is a six dimensional vector. [Matrix **A** would be a diagonal matrix that looks like this:]\n",
    "\n",
    "$\\large \\begin{matrix}\n",
    "a_{11} & & \\\\\n",
    "a_{21} & a_{22} & \\\\ \n",
    "a_{31} & a_{32} & a_{33}\n",
    "\\end{matrix}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
